{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC as SVMClassifier\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "def sort_by_target(mnist):\n",
    "    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]\n",
    "    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]\n",
    "    mnist.data[:60000] = mnist.data[reorder_train]\n",
    "    mnist.target[:60000] = mnist.target[reorder_train]\n",
    "    mnist.data[60000:] = mnist.data[reorder_test + 60000]\n",
    "    mnist.target[60000:] = mnist.target[reorder_test + 60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get digit MNIST handwritten digit dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "mnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings\n",
    "#sort_by_target(mnist) # fetch_openml() returns an unsorted dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and labels of MNIST dataset\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "# Print to show there are 7000 images with 28x28 pixels\n",
    "print(\"Image Data Shape:\" , X.shape)\n",
    "\n",
    "# Print to show there are 7000 labels (integers from 0-9)\n",
    "print(\"Label Data Shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print target classes in the dataset\n",
    "print(\"Classes:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "some_digit = X[1]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_row = 2\n",
    "num_col = 5# plot images\n",
    "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for i in np.unique(y):\n",
    "    ax = axes[i//num_col, i%num_col]\n",
    "    some_digit = X[i]\n",
    "    some_digit_image = some_digit.reshape(28, 28)\n",
    "    ax.imshow(some_digit_image, cmap = mpl.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "    ax.set_title('Label: {}'.format(y[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into train and test partitions\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.20)\n",
    "\n",
    "print(\"Train Data Size: {}\".format(y_train.size))\n",
    "print(\"Test Data Size: {}\".format(y_test.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BINARY CLASSIFICATION PROBLEM (WHETHER THE DIGIT IS 5 or NOT)\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_relu=MLPClassifier(solver='sgd', hidden_layer_sizes=(4,3,2), activation='relu', \n",
    "                   max_iter=30, verbose=True, early_stopping=True)\n",
    "mlp_tanh=MLPClassifier(solver='sgd', hidden_layer_sizes=(4,3, 2), activation='tanh', \n",
    "                   max_iter=30,verbose=True,early_stopping=True)\n",
    "mlp_sigmoid=MLPClassifier(solver='sgd', hidden_layer_sizes=(4,3,2), activation='logistic', \n",
    "                   max_iter=30,verbose=True,early_stopping=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTRAINING for MLP with RELU ACTIVATION STARTED:\\n\")\n",
    "mlp_relu.fit(x_train, y_train_5)\n",
    "\n",
    "print(\"\\nTRAINING for MLP with TANH ACTIVATION STARTED:\\n\")\n",
    "mlp_tanh.fit(x_train, y_train_5)\n",
    "\n",
    "print(\"\\nTRAINING for MLP with SIGMOID ACTIVATION STARTED:\\n\")\n",
    "mlp_sigmoid.fit(x_train, y_train_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Loss Curves on MLP Training\")\n",
    "plt.plot(mlp_sigmoid.loss_curve_, label='MLP with Sigmoid Activation')\n",
    "plt.plot(mlp_relu.loss_curve_, label='MLP with ReLU Activation')\n",
    "plt.plot(mlp_tanh.loss_curve_, label='MLP with Tanh Activation')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_relu = mlp_relu.predict_proba(x_test)\n",
    "y_scores_tanh = mlp_tanh.predict_proba(x_test)\n",
    "y_scores_sigmoid = mlp_sigmoid.predict_proba(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Probability of being 5 on test samples\n",
    "num_row = 2\n",
    "num_col = 5# plot images\n",
    "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col, 2*num_row))\n",
    "for i in np.unique(y):\n",
    "    ax = axes[i//num_col, i%num_col]\n",
    "    some_digit = X[32+i]\n",
    "    prob=mlp_tanh.predict_proba([some_digit])\n",
    "    some_digit_image = some_digit.reshape(28, 28)\n",
    "    ax.set_title('P(5): {:.2f}'.format(prob[0,1]))\n",
    "    ax.imshow(some_digit_image, cmap = mpl.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of ROC curves for different activation functions\n",
    "fpr_tanh, tpr_tanh, thresholds_tanh = roc_curve(y_test_5, y_scores_tanh[:,1])\n",
    "fpr_sigmoid, tpr_sigmoid, thresholds_sigmoid = roc_curve(y_test_5, y_scores_sigmoid[:,1])\n",
    "fpr_relu, tpr_relu, thresholds_relu = roc_curve(y_test_5, y_scores_relu[:,1])\n",
    "\n",
    "   \n",
    "plt.title(\"ROC Curve of predicting 5 for different activation fucntions on MLP\")\n",
    "plt.plot(fpr_tanh,tpr_tanh, label='MLP with Tanh Activation')\n",
    "plt.plot(fpr_sigmoid,tpr_sigmoid, label='MLP with Sigmoid Activation')\n",
    "plt.plot(fpr_relu,tpr_relu, label='MLP with ReLU Activation')\n",
    "plt.legend()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEASURING EFFECT OF STANDARDIZATION\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train.astype(np.float64))\n",
    "x_test_scaled = scaler.transform(x_test.astype(np.float64))\n",
    "\n",
    "print(\"\\nTRAINING for MLP with TANH ACTIVATION STARTED:\\n\")\n",
    "mlp_tanh.fit(x_train_scaled, y_train_5)\n",
    "\n",
    "y_scaled_scores_tanh = mlp_tanh.predict_proba(x_test_scaled)\n",
    "\n",
    "fpr_sclaed_tanh, tpr_scaled_tanh, thresholds_scaled_tanh = roc_curve(y_test_5, y_scaled_scores_tanh[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title(\"ROC Curve of predicting 5 with/without standardization on MLP\")\n",
    "plt.plot(fpr_tanh,tpr_tanh, label='MLP without standardization')\n",
    "plt.plot(fpr_sclaed_tanh,tpr_scaled_tanh, label='MLP with standardization')\n",
    "plt.legend()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Multi-class classifier\n",
    "print(\"\\nTRAINING for MLP with TANH ACTIVATION STARTED:\\n\")\n",
    "mlp_tanh=MLPClassifier(solver='sgd', hidden_layer_sizes=(20, 15, 10), activation='tanh', \n",
    "                   max_iter=60,verbose=True,early_stopping=True)\n",
    "\n",
    "mlp_tanh.fit(x_train_scaled, y_train)\n",
    "y_pred_scaled_tanh = mlp_tanh.predict(x_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the accuracy of system on test data\n",
    "accuracy=accuracy_score(y_test,y_pred_scaled_tanh)\n",
    "print(\"Test Accuracy: {}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(mlp_tanh, x_test_scaled, y_test, display_labels=np.unique(y))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# EXTRA\n",
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, **options)\n",
    "    #plt.axis(\"off\")\n",
    "    \n",
    "    \n",
    "cl_a, cl_b = 7, 9\n",
    "X_aa = x_test_scaled[(y_test == cl_a) & (y_pred_scaled_tanh == cl_a)]\n",
    "X_ab = x_test_scaled[(y_test == cl_a) & (y_pred_scaled_tanh == cl_b)]\n",
    "X_ba = x_test_scaled[(y_test == cl_b) & (y_pred_scaled_tanh == cl_a)]\n",
    "X_bb = x_test_scaled[(y_test == cl_b) & (y_pred_scaled_tanh == cl_b)]\n",
    "\n",
    "plt.figure(figsize=(28,28))\n",
    "plt.subplot(221); plot_digits(X_aa[1:10], images_per_row=3)\n",
    "plt.subplot(222); plot_digits(X_ab[1:10], images_per_row=3)\n",
    "plt.subplot(223); plot_digits(X_ba[1:10], images_per_row=3)\n",
    "plt.subplot(224); plot_digits(X_bb[1:10], images_per_row=3)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
